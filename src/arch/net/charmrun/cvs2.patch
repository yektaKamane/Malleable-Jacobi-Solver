Index: src/arch/net/charmrun/charmrun.c
===================================================================
RCS file: /cvsroot/charm/src/arch/net/charmrun/charmrun.c,v
retrieving revision 1.159
diff -u -r1.159 charmrun.c
--- src/arch/net/charmrun/charmrun.c	21 Sep 2009 18:51:22 -0000	1.159
+++ src/arch/net/charmrun/charmrun.c	26 Jan 2010 21:34:52 -0000
@@ -17,6 +17,7 @@
 #include <fcntl.h>
 #include <time.h>
 #include <assert.h>
+#include <math.h>
 #if CMK_BPROC
 #include <sys/bproc.h>
 #endif
@@ -579,6 +580,34 @@
   return 0;
 }
 
+char **
+dupargv (argv)
+     char **argv;
+{
+  int argc;
+  char **copy;
+  
+  if (argv == NULL)
+    return NULL;
+  
+  /* the vector */
+  for (argc = 0; argv[argc] != NULL; argc++);
+  copy = (char **) malloc ((argc + 1) * sizeof (char *));
+  if (copy == NULL)
+    return NULL;
+  
+  /* the strings */
+  for (argc = 0; argv[argc] != NULL; argc++)
+    {
+      int len = strlen (argv[argc]);
+      copy[argc] = malloc (sizeof (char *) * (len + 1));
+      strcpy (copy[argc], argv[argc]);
+    }
+  copy[argc] = NULL;
+  return copy;
+}
+
+
 /****************************************************************************
  * 
  * ARG
@@ -616,6 +645,8 @@
 int   arg_local;	/* start node programs directly by exec on localhost */
 int   arg_batch_spawn;  /* control starting node programs, several at a time */
 int   arg_scalable_start;
+int	arg_hierarchical_start;
+int	arg_child_charmrun;
 
 int   arg_help;		/* print help message */
 int   arg_ppn;		/* pes per node */
@@ -635,7 +666,6 @@
 int arg_ssh_display;
 char *arg_mylogin;
 #endif
-int   arg_no_va_rand;
 
 char *arg_nodeprog_a;
 char *arg_nodeprog_r;
@@ -679,6 +709,8 @@
   pparam_flag(&arg_local,	local_def, "local", "Start node programs locally without daemon");
   pparam_int(&arg_batch_spawn,	 0, "batch", "Rsh several node programs at a time, avoiding overloading charmrun pe");
   pparam_flag(&arg_scalable_start, 0, "scalable-start", "scalable start");
+  pparam_flag(&arg_hierarchical_start, 0, "hierarchical-start", "hierarchical start");
+  pparam_flag(&arg_child_charmrun, 0, "child-charmrun", "child charmrun");
   pparam_flag(&arg_usehostname,  0, "usehostname", "Send nodes our symbolic hostname instead of IP address");
   pparam_str(&arg_charmrunip,    0, "useip",      "Use IP address provided for charmrun IP");
 #if CMK_USE_RSH
@@ -722,7 +754,8 @@
   pparam_str(&arg_runscript,    0, "runscript", "script to run node-program with");
   pparam_flag(&arg_help,	0, "help", "print help messages");
   pparam_int(&arg_ppn,          0, "ppn",             "number of pes per node");
-  pparam_flag(&arg_no_va_rand,   0, "no-va-randomization",   "Disables randomization of the virtual address  space");
+
+  arg_argv = dupargv(argv);
 
   if (pparam_parsecmd('+', argv) < 0) {
     fprintf(stderr,"ERROR> syntax: %s\n",pparam_error);
@@ -742,15 +775,28 @@
     /*exit(0);*/
   }
 
-  arg_argv = argv+1; /*Skip over charmrun (0) here and program name (1) later*/
+ if (!(arg_hierarchical_start && !arg_child_charmrun)){
+		 arg_argv = argv+1; /*Skip over charmrun (0) here and program name (1) later*/
+ }
   arg_argc = pparam_countargs(arg_argv);
   if (arg_argc<1) {
     fprintf(stderr,"ERROR> You must specify a node-program.\n");
     pparam_printdocs();
     exit(1);
   }
-  arg_argv++; arg_argc--;
 
+	if (!(arg_hierarchical_start && !arg_child_charmrun)){
+		//Removing nodeprogram from the list
+		arg_argv++; arg_argc--;
+	}
+	else{
+		//Removing charmrun from parameters	
+		arg_argv++;arg_argc--;
+ 		arg_argv[arg_argc++]="++child-charmrun";
+		arg_argv[arg_argc] = NULL;
+	}
+
+					
   if (arg_server_port || arg_server_auth) arg_server=1;
 
   if (arg_debug || arg_debug_no_pause) {
@@ -836,7 +882,14 @@
       fprintf(stderr, "Charmrun> Error: ++scalable-start does not support debugging mode. \n");
       exit(1);
     }
-  }
+	}
+  if (arg_hierarchical_start) {
+    printf("Charmrun> hierarchial scalable start enabled. \n");
+    if (arg_debug || arg_debug_no_pause) {
+      fprintf(stderr, "Charmrun> Error: ++hierarchial-start does not support debugging mode. \n");
+      exit(1);
+    }
+	}
 }
 
 /****************************************************************************
@@ -902,6 +955,7 @@
   /*These fields are set during node-startup*/
   int     dataport;/*UDP port number*/
   SOCKET  ctrlfd;/*Connection to control port*/
+/*	nodetab_host * parent; Parent charmrun.. in hierarchical startup*/
 #if CMK_USE_RSH
   char    *shell;  /*Rsh to use*/
   char    *debugger ; /*Debugger to use*/
@@ -1062,6 +1116,28 @@
     }
   }
 }
+/* Sets the parent field of hosts to point to their parent charmrun. The root charmrun will create children for all hosts which are parent of at kleast one other host*/
+int branchfactor;
+int nodes_per_child;
+void nodetab_init_hierarchical_start(void)
+{
+	branchfactor = ceil(sqrt(nodetab_rank0_size));
+	nodes_per_child = round(nodetab_rank0_size*1.0/branchfactor);
+	printf("branchfactor = %d per child = %d\n", branchfactor, nodes_per_child);
+/*	int i;
+	for(i =0; i< branchfactor-1; i++)
+	{
+		int j;
+		for(j = 0; j<branchfactor; j++)
+		{
+			nodetab_table[i*branchfactor+j]-> parent = nodetable_table[i*branchfactor];
+		}
+	}
+	int k;
+	for( k =i*branchfactor;k<arg_requested_pes; k++)
+		nodetab_table[k]-> parent = nodetable_table[i*branchfactor];
+	*/
+}
 
 void nodetab_init()
 {
@@ -1163,6 +1239,8 @@
 #ifdef _FAULT_MLOG_
 	loaded_max_pe = arg_requested_pes-1;
 #endif
+	if(arg_hierarchical_start) 
+		nodetab_init_hierarchical_start();		
 
 }
 
@@ -1383,37 +1461,23 @@
   pe=ChMessageInt(h.hdr.pe);
   reqBytes=ChMessageInt(h.hdr.len);
 
-  if (pe<=-nodetab_size || pe>=nodetab_size) {
-    /*Treat out of bound values as errors. Helps detecting bugs*/
-    if (pe==-nodetab_size) fprintf(stderr,"Invalid processor index in CCS request: are you trying to do a broadcast instead?");
-    else fprintf(stderr,"Invalid processor index in CCS request.");
-    CcsServer_sendReply(&h.hdr,0,0);
-    free(reqData);
-    return;
-  }
-  else if (pe == -1) {
-    /*Treat -1 as broadcast and sent to 0 as root of the spanning tree*/
-    pe = 0;
-  }
-  else if (pe < -1) {
-    /*Treat negative values as multicast to a number of processors specified by -pe.
-      The pes to multicast to follows sits at the beginning of reqData*/
-    reqBytes -= pe * sizeof(ChMessageInt_t);
-    pe = ChMessageInt(*(ChMessageInt_t*)reqData);
+  if (pe<0 || pe>=nodetab_size) {
+	pe=0;
+	h.hdr.pe=ChMessageInt_new(pe);
   }
-  
+
   if (! check_stdio_header(&h.hdr)) {
 
 #define LOOPBACK 0
 #if LOOPBACK /*Immediately reply "there's nothing!" (for performance testing)*/
-    CcsServer_sendReply(&h.hdr,0,0);
+  CcsServer_sendReply(&h.hdr,0,0);
 #else
-    /*Fill out the charmrun header & forward the CCS request*/
-    ChMessageHeader_new("req_fw",sizeof(h.hdr)+reqBytes,&h.ch);  
-
-    bufs[0]=&h; lens[0]=sizeof(h);
-    bufs[1]=reqData; lens[1]=reqBytes;
-    skt_sendV(nodetab_ctrlfd(pe),2,bufs,lens);
+  /*Fill out the charmrun header & forward the CCS request*/
+  ChMessageHeader_new("req_fw",sizeof(h.hdr)+reqBytes,&h.ch);  
+  
+  bufs[0]=&h; lens[0]=sizeof(h);
+  bufs[1]=reqData; lens[1]=reqBytes;
+  skt_sendV(nodetab_ctrlfd(pe),2,bufs,lens);
 
 #endif
   }
@@ -1547,6 +1611,7 @@
 int req_handle_initnodetab(ChMessage *msg,SOCKET fd)
 {
 	ChMessageHeader hdr;
+	/* TODO: Need to see if it is correct to say nodetab_ranl0_size*/
 	ChMessageInt_t nNodes=ChMessageInt_new(nodetab_rank0_size);
 	ChMessageHeader_new("initnodetab",sizeof(ChMessageInt_t)+
 			    sizeof(ChNodeinfo)*nodetab_rank0_size,&hdr);
@@ -1557,7 +1622,91 @@
 			
 	return REQ_OK;
 }
+/*Get the array of node numbers, IPs, and ports.
+This is used by the node-programs to talk to one another.
+*/
+int nodes_to_fork;
+static int parent_charmrun_fd = -1;
+int req_handle_initnodedistribution(ChMessage *msg,SOCKET fd, int client)
+{
+	nodes_to_fork = nodes_per_child; /* rounding should help in better load distribution*/
+
+	if(client == branchfactor -1)	
+		nodes_to_fork = nodetab_rank0_size- client*nodes_per_child;
+	int k;
+	ChMessageInt_t * nodemsg = (ChMessageInt_t *)malloc(nodes_to_fork*sizeof(ChMessageInt_t)); 
+	for(k =0; k <nodes_to_fork; k++)
+			nodemsg[k] = ChMessageInt_new(nodetab_rank0_table[client*nodes_per_child+k]);
+	ChMessageHeader hdr;
+	ChMessageInt_t nNodes=ChMessageInt_new(nodes_to_fork);
+	ChMessageHeader_new("initnodetab",sizeof(ChMessageInt_t)+
+			    sizeof(ChMessageInt_t)*nodes_to_fork,&hdr);
+	skt_sendN(fd,(const char *)&hdr,sizeof(hdr));
+	skt_sendN(fd,(const char *)&nNodes,sizeof(nNodes));
+	/*might need conversion to Chmessage */ 
+	skt_sendN(fd,(const char *)nodemsg,nodes_to_fork*sizeof(ChMessageInt_t));
+	free(nodemsg);		
+	return REQ_OK;
+}
+
 
+ChSingleNodeinfo * myNodesInfo;
+int	send_myNodeInfo_to_parent()
+{
+	ChMessageHeader hdr;
+	ChMessageInt_t nNodes=ChMessageInt_new(nodetab_rank0_size);
+	ChMessageHeader_new("initnodetab",sizeof(ChMessageInt_t)+
+			    sizeof(ChSingleNodeinfo)*nodetab_rank0_size,&hdr);
+	skt_sendN(parent_charmrun_fd,(const char *)&hdr,sizeof(hdr));
+	skt_sendN(parent_charmrun_fd,(const char *)&nNodes,sizeof(nNodes));
+	skt_sendN(parent_charmrun_fd,(const char *)myNodesInfo,
+		  sizeof(ChSingleNodeinfo)*nodetab_rank0_size);
+			
+	return REQ_OK;
+}
+void forward_nodetab_to_children()
+{
+	/*it just needs to receive and copy the nodetab info if required and send it as it is to its nodes */	
+if (!skt_select1(parent_charmrun_fd,1200*1000)){
+	//	CmiAbort("Timeout waiting for nodetab!\n");
+	//	Timeout mechanism to be inserted
+	exit(0);
+	}
+ChMessage msg;
+ChMessage_recv(parent_charmrun_fd,&msg);
+
+ChMessageInt_t * nodelistmsg = (ChMessageInt_t *)msg.data;			
+int nodetab_Nodes = ChMessageInt(nodelistmsg[0]);
+int client;
+for (client=0;client<nodetab_rank0_size;client++)	{
+	SOCKET fd = req_clients[client];
+	ChMessageHeader hdr;
+	/* TODO: Need to see if it is correct to say nodetab_rank0_size*/
+	ChMessageInt_t nNodes=ChMessageInt_new(nodetab_Nodes);
+	ChMessageHeader_new("initnodetab",sizeof(ChMessageInt_t)+
+			    sizeof(ChNodeinfo)*nodetab_Nodes,&hdr);
+	skt_sendN(fd,(const char *)&hdr,sizeof(hdr));
+	skt_sendN(fd,(const char *)&nodetab_Nodes,sizeof(nodetab_Nodes));
+	skt_sendN(fd,(const char *)&nodelistmsg[1],
+		  sizeof(ChNodeinfo)*nodetab_Nodes);
+}
+//#if CMK_USE_IBVERBS	
+//#else
+//TODO : Process this message
+}
+/*Parent Charmrun receives the nodetab from child and processes it. msg contain array of ChSingleNodeInfo*/
+void receive_nodeset_from_child(ChMessage *msg, SOCKET fd)
+{
+	ChMessageInt_t * n32 = (ChMessageInt_t *)msg->data;	
+int numOfNodes =ChMessageInt(n32[0]); /*TODO*/
+	/*TODP : Introduce error checks in msg format*/
+ChSingleNodeinfo *childNodeInfo = (ChSingleNodeinfo*) (n32+1);
+	int k;
+	printf("number = %d\n", numOfNodes);
+	/* generic function for this is req_handle_nodetab*/
+	for(k = 0; k<numOfNodes; k++)
+			nodeinfo_add(childNodeInfo+k,fd);
+}
 /* Check this return code from "printf". */
 static void checkPrintfError(int err) {
   if (err<0) {
@@ -1932,7 +2081,12 @@
 static unsigned int server_port;
 static char server_addr[1024];/* IP address or hostname of charmrun*/
 static SOCKET server_fd;
-
+static skt_ip_t parent_charmrun_IP;
+static int parent_charmrun_port;
+static int parent_charmrun_pid;
+static int dataport;
+static SOCKET dataskt;
+int charmrun_phase =0;
 int client_connect_problem(int code,const char *msg)
 {/*Called when something goes wrong during a client connect*/
 
@@ -1944,6 +2098,8 @@
 
 /** return 1 if connection is openned succesfully with client**/
 int errorcheck_one_client_connect(int client){
+	/* Child charmruns are already connected - Do we need to conect again*/	
+	if(arg_hierarchical_start && !arg_child_charmrun && charmrun_phase ==1) return 1;	
 	unsigned int clientPort;/*These are actually ignored*/
 	skt_ip_t clientIP;
 	if (arg_verbose) printf("Charmrun> Waiting for %d-th client to connect.\n",client);
@@ -1991,7 +2147,18 @@
 	
 };
 #endif
+int nodeCount = 0;
+void add_singlenodeinfo_to_mynodeinfo(ChMessage * msg)
+{
+	/*add to myNodesInfo */				
+	ChSingleNodeinfo *nodeInfo = (ChSingleNodeinfo *)msg->data;
+	/* TODO: better mechanism*/
+	/* need to change nodeNo */
+	myNodesInfo[nodeCount].nodeNo = ChMessageInt_new(nodetab_rank0_table[ChMessageInt(nodeInfo->nodeNo)]);
+	myNodesInfo[nodeCount++].info = nodeInfo->info;
+}
 
+/*int charmrun_phase =0; meaningful for main charmun to decide what to receive*/
 void req_set_client_connect(int start,int end) {
 	fd_set sockset;
 	ChMessage msg;
@@ -2005,10 +2172,11 @@
 	finished=malloc((end-start)*sizeof(int));
 	for(i=0;i<(end-start);i++)
 		finished[i]=0;
-
+	if(arg_child_charmrun) myNodesInfo = malloc(sizeof(ChSingleNodeinfo)*nodetab_rank0_size); 
 	done=0;
 	while(!done) {
 		/* check server socket for messages */
+		/* TODO:Do we need to do this in second phase as well that is when the child charmruns are already connected*/	
 		while(curclientstart==curclientend||skt_select1(server_fd,1)!=0) {
 			errorcheck_one_client_connect(curclientend++);
 		}
@@ -2017,7 +2185,20 @@
 			if(req_clients[client]>0) {
 				if(skt_select1(req_clients[client],1)!=0) {
 					ChMessage_recv(req_clients[client],&msg);
+					if(arg_hierarchical_start && !arg_child_charmrun)
+					{
+									if(charmrun_phase ==1) 
+										receive_nodeset_from_child(&msg, req_clients[client]);
+									//here we need to decide based upon the phase
+					}
+					else /* hier-start with 2nd leval*/
+					{
+					/* Uncomment me later				
 					req_handle_initnode(&msg,req_clients[client]);
+					*/
+					add_singlenodeinfo_to_mynodeinfo(&msg);				
+					}
+
 					finished[client-start]=1;
 				}
 			}
@@ -2038,7 +2219,9 @@
 	free(finished);
 }
 
-
+/* msg would be an array of ChSingleNodeinfo*/
+				
+				
 /* allow one client to connect */
 void req_one_client_connect(int client)
 {
@@ -2091,12 +2274,11 @@
 }
 #endif
 
-
 /*Wait for all the clients to connect to our server port*/
 void req_client_connect(void)
 {
 	int client;
-	nodeinfo_allocate();
+	if(!arg_hierarchical_start) nodeinfo_allocate();
 	req_nClients=nodetab_rank0_size;
 	req_clients=(SOCKET *)malloc(req_nClients*sizeof(SOCKET));
 	for(client=0;client<req_nClients;client++)
@@ -2121,11 +2303,72 @@
 	exchange_qpdata_clients();
 	send_clients_nodeinfo_qpdata();
 #else
-	for (client=0;client<req_nClients;client++)
+		/* first we need to send data to parent charmrun and then send the nodeinfo to the clients*/
+	send_myNodeInfo_to_parent();
+//	req_handle_initnodetab(NULL,parent_charmrun_fd);
+	/*then receive from root */
+	forward_nodetab_to_children();
+//	send_nodetab_parent(NULL,req_clients[client]);
+/*	for (client=0;client<req_nClients;client++)	{			
 		req_handle_initnodetab(NULL,req_clients[client]);
+	}*/
 #endif
 	if (arg_verbose) printf("Charmrun> IP tables sent.\n");
 }
+/*Wait for all the clients to connect to our server port, then collect and send nodetable to all */
+void req_charmrun_connect(void)
+{
+	int client;
+	nodeinfo_allocate();
+	req_nClients=branchfactor;
+	req_clients=(SOCKET *)malloc(req_nClients*sizeof(SOCKET));
+	for(client=0;client<req_nClients;client++)
+		req_clients[client]=-1;
+	
+	skt_set_abort(client_connect_problem);
+	
+#if CMK_IBVERBS_FAST_START
+	for (client=0;client<req_nClients;client++){
+		req_one_client_partinit(client);
+	}
+	for (client=0;client<req_nClients;client++){
+		read_initnode_one_client(client);
+	}
+#else
+	req_set_client_connect(0,req_nClients);
+	/* also need to process received nodesets JIT */
+#endif
+	
+        if (portOk == 0) exit(1);
+	if (arg_verbose) printf("Charmrun> All clients connected.\n");
+#if CMK_USE_IBVERBS
+	exchange_qpdata_clients();
+	send_clients_nodeinfo_qpdata();
+#else
+	for (client=0;client<req_nClients;client++)	{
+					// add flag to check what leval charmrun it is and what phase
+		req_handle_initnodedistribution(NULL, req_clients[client], client);
+//		req_handle_initnodetab(NULL,req_clients[client]);
+	}
+
+	/* Now receive the nodetab from child charmruns*/
+	charmrun_phase = 1;
+	/*for(client=0;client<req_nClients;client++)
+		req_clients[client]=-1;*/
+	
+	skt_set_abort(client_connect_problem);
+
+	req_set_client_connect(0,req_nClients);
+
+	/* Already processed, so send*/
+	for (client=0;client<req_nClients;client++)	{			
+		req_handle_initnodetab(NULL,req_clients[client]);
+	}
+
+#endif
+	if (arg_verbose) printf("Charmrun> IP tables sent.\n");
+}
+
 
 #ifndef CMK_BPROC
 
@@ -2164,7 +2407,7 @@
 
 #if CMK_IBVERBS_FAST_START
 		for (c=clientstart;c<client;c++) { 
-        		req_one_client_partinit(c);
+        		req_one_cliein(nt_partinit(c);
 		}
 #else
 		req_set_client_connect(clientstart,client);
@@ -2229,6 +2472,140 @@
 #endif
 }
 
+/* Function copied from machine.c file */
+void parse_netstart(void)
+{
+  char *ns;
+  int nread;
+  int port;
+	int _mynode;
+  ns = getenv("NETSTART");
+  if (ns!=0) 
+  {/*Read values set by Charmrun*/
+        char parent_charmrun_name[1024];
+        nread = sscanf(ns, "%d%s%d%d%d",
+                 &_mynode,
+                 parent_charmrun_name, &parent_charmrun_port,
+                 &parent_charmrun_pid, &port);
+	parent_charmrun_IP=skt_lookup_ip(parent_charmrun_name);
+
+        if (nread!=5) {
+                fprintf(stderr,"Error parsing NETSTART '%s'\n",ns);
+                exit(1);
+        }
+  } 
+#if CMK_USE_IBVERBS | CMK_USE_IBUD
+	char *cmi_num_nodes = getenv("CmiNumNodes");
+	if(cmi_num_nodes != NULL){
+		sscanf(cmi_num_nodes,"%d",&_Cmi_numnodes);
+	}
+#endif	
+}
+
+/* Receive nodes for which I am responsible*/
+void my_nodetab_store(ChMessage *msg)
+{
+	ChMessageInt_t * nodelistmsg = (ChMessageInt_t *)msg->data;			
+	nodetab_rank0_size = ChMessageInt(nodelistmsg[0]);
+	int k;
+	for(k =0; k<nodetab_rank0_size ; k++)
+	{
+		nodetab_rank0_table[k] = ChMessageInt(nodelistmsg[k+1]);
+	}
+}
+
+
+
+void nodelist_obtain(void)
+{
+  ChMessage nodelistmsg; /* info about all nodes*/
+  /*Contact charmrun for machine info.*/
+
+#if CMK_USE_IBVERBS
+	{
+/*		int qpListSize = (_Cmi_numnodes-1)*sizeof(ChInfiAddr);
+		me.info.qpList = malloc(qpListSize);
+		copyInfiAddr(me.info.qpList);
+		MACHSTATE1(3,"me.info.qpList created and copied size %d bytes",qpListSize);
+		ctrl_sendone_nolock("initnode",(const char *)&me,sizeof(me),(const char *)me.info.qpList,qpListSize);
+		free(me.info.qpList);
+*/	}
+#else
+	/*The nPE and IP fields are set by charmrun--
+	  these values don't matter. */
+  
+	/*Send our node info. to charmrun.
+  	CommLock hasn't been initialized yet-- 
+  	use non-locking version*/
+	ChMessageHeader hdr;
+	ChMessageInt_t dummy=ChMessageInt_new(nodetab_rank0_size);
+	ChMessageHeader_new("initnodetab",sizeof(ChMessageInt_t),&hdr);
+	skt_sendN(parent_charmrun_fd,(const char *)&hdr,sizeof(hdr));
+	skt_sendN(parent_charmrun_fd,(const char *)&dummy,sizeof(dummy));
+
+ #endif	//CMK_USE_IBVERBS
+
+  
+  	/*We get the other node addresses from a message sent
+  	  back via the charmrun control port.*/
+  	if (!skt_select1(parent_charmrun_fd,1200*1000)){
+	//	CmiAbort("Timeout waiting for nodetab!\n");
+	//	Timeout mechanism to be inserted
+	exit(0);
+	}
+  	ChMessage_recv(parent_charmrun_fd,&nodelistmsg);
+  
+//#if CMK_USE_IBVERBS	
+//#else
+//TODO : Process this message
+  my_nodetab_store(&nodelistmsg);
+  ChMessage_free(&nodelistmsg);
+//#endif	
+}
+
+
+void init_mynodes(void)
+{
+parse_netstart();
+if (!skt_ip_match(parent_charmrun_IP,_skt_invalid_ip)) {
+  //	set_signals();
+#if CMK_USE_TCP
+  	dataskt=skt_server(&dataport);
+		/*
+#elif !CMK_USE_GM && !CMK_USE_MX
+
+
+  	dataskt=skt_datagram(&dataport, Cmi_os_buffer_size);
+		*/
+#else
+          /* GM and MX do not need to create any socket for communication */
+        dataskt=-1;
+#endif
+/*				
+	MACHSTATE2(5,"skt_connect at dataskt:%d Cmi_charmrun_port:%d",dataskt, Cmi_charmrun_port);
+ */
+	parent_charmrun_fd = skt_connect(parent_charmrun_IP, parent_charmrun_port, 1800);
+/*	MACHSTATE2(dd5,"Opened connection to charmrun at socket %d, dataport=%d", Cmi_charmrun_fd, dataport);
+	CmiStdoutInit();
+	*/
+  } else {/*Standalone operation*/
+  	printf("Charm++: standalone mode (not using charmrun)\n");
+  	dataskt=-1;
+  	parent_charmrun_fd=-1;
+  }
+
+//  CmiMachineInit(argv);
+  nodelist_obtain();
+}
+
+
+
+	
+	
+	
+				
+
+	
 /****************************************************************************
  *
  *  The Main Program
@@ -2236,6 +2613,7 @@
  ****************************************************************************/
 void start_nodes_daemon(void);
 void start_nodes_rsh(void);
+void start_next_level_charmruns(void);
 #if CMK_BPROC
 void nodetab_init_for_scyld(void);
 void start_nodes_scyld(void);
@@ -2258,6 +2636,7 @@
   ping_developers();
   /* Compute the values of all constants */
   arg_init(argc, argv);
+ 
   if(arg_verbose) fprintf(stderr, "Charmrun> charmrun started...\n");
 #if CMK_BPROC
   /* check scyld configuration */
@@ -2269,12 +2648,21 @@
   /* Initialize the node-table by reading nodesfile */
   nodetab_init();
 #endif
-
-  /* Start the server port */
+/* Start the server port */
   req_start_server();
   
   /* Initialize the IO module */
   input_init();
+
+ if(arg_child_charmrun)
+	{
+					printf("Second-leval Charmrun");
+				//	sleep(90);
+					init_mynodes(); /* contacts root charmrun and gets list  of nodes to start*/
+
+				//	exit(0);
+	}
+
   
   /* start the node processes */
   if (0!=getenv("CONV_DAEMON"))
@@ -2288,7 +2676,12 @@
 #endif
     if (!arg_local) {
       if (!arg_batch_spawn)
+		{
+			if(arg_hierarchical_start && !arg_child_charmrun){	
+		  start_next_level_charmruns();}
+			else 
         start_nodes_rsh();
+		}
       else
         req_client_start_and_connect();
     }
@@ -2317,14 +2710,21 @@
 #if !CMK_RSH_KILL
   if (!arg_batch_spawn) finish_nodes();
 #endif
-  if (!arg_batch_spawn) req_client_connect();
+//	Uncomment me
+  if (!arg_batch_spawn){
+		if(arg_hierarchical_start && !arg_child_charmrun)			
+		  req_charmrun_connect();
+		else 
+			req_client_connect();
+	}
 #if CMK_RSH_KILL
   kill_nodes();
 #endif
   if(arg_verbose) fprintf(stderr, "Charmrun> node programs all connected\n");
 
   /* enter request-service mode */
-  while (1) req_poll();
+	//Uncomment me
+  // while (1) req_poll();
 }
 
 /*This little snippet creates a NETSTART 
@@ -2979,10 +3379,6 @@
   } else {
     if (arg_runscript)
        fprintf(f,"\"%s\" ",arg_runscript);
-    if (arg_no_va_rand) {
-      if(arg_verbose) fprintf(stderr, "Charmrun> setarch -R is used.\n");
-      fprintf(f,"setarch `uname -m` -R ");
-    }
     fprintf(f,"\"%s\" ",arg_nodeprog_r);
     fprint_arg(f,argv);
     if (nodetab_nice(nodeno) != -100) {
@@ -3112,6 +3508,46 @@
   close(fderr[1]);
 }
 
+void start_next_level_charmruns()
+{
+	
+   static char buf[1024];
+	 sprintf(buf,"%s%s%s",arg_currdir_a,DIRSEP,"charmrun");
+   arg_nodeprog_a = strdup(buf);
+	 int client;
+	 int nextIndex =0;
+	 //rsh_pids=(int *)malloc(sizeof(int)*branchfactor);
+	 client=0;
+	 while(nextIndex<branchfactor){
+	 int rank0no = client;
+	 int pe=nodetab_rank0_table[rank0no];
+     FILE *f;
+     char startScript[200];
+     sprintf(startScript,"/tmp/charmrun.%d.%d",getpid(),pe);
+     f=fopen(startScript,"w");
+     if (f==NULL) {
+       /* now try current directory */
+       sprintf(startScript,"charmrun.%d.%d",getpid(),pe);
+       f=fopen(startScript,"w");
+       if (f==NULL) {
+     	 fprintf(stderr,"Charmrun> Can not write file %s!\n", startScript);
+     	 exit(1);
+       }
+     }
+     rsh_script(f,pe,rank0no,arg_argv,0);
+     fclose(f);
+    if (!rsh_pids)
+       rsh_pids=(int *)malloc(sizeof(int)*branchfactor);
+     rsh_pids[nextIndex++] = rsh_fork(pe,startScript);
+	 	 client += nodes_per_child;
+
+	}
+}
+
+								
+				
+
+
 /* returns pid */
 void start_one_node_rsh(int rank0no)
 {
@@ -3151,7 +3587,7 @@
 		} while(clientgroup<nodetab_rank0_size&&(!strcmp(nodetab_name(clientgroup),nodetab_name(client))));
 	}
 #endif
-
+/* might need to change this */
 	nodetab_getnodeinfo(client)->forks=clientgroup-client-1; /* already have 1 process launching */
 
 	start_one_node_rsh(client);
@@ -3189,7 +3625,7 @@
 					if (!WEXITSTATUS(status)) { /* good */
 						rsh_pids[i]=0; /* process is finished */
 					} else {
-  						host=nodetab_name(nodetab_rank0_table[i]);
+  						host=nodetab_name(nodetab_rank0_table[i]); /* need to change this to branchfactor multiplication for main charmrun in hierarchical-start*/
 						fprintf(stderr,"Charmrun> Error %d returned from rsh (%s:%d)\n",
 						WEXITSTATUS(status),host,i);
 						exit(1);
@@ -3202,6 +3638,9 @@
 
 void finish_nodes()
 {
+	if(arg_hierarchical_start && !arg_child_charmrun)
+			finish_set_nodes(0, branchfactor);
+	else 
 	finish_set_nodes(0,nodetab_rank0_size);
 	free(rsh_pids);
 }

